{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28753aa1",
   "metadata": {},
   "source": [
    "Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2795d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.12).\n",
      "Resuming download from 234881024 bytes (182087059 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/andrewmvd/face-mask-detection?dataset_version_number=1 (234881024/416968083) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398M/398M [04:49<00:00, 629kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\lenovo\\.cache\\kagglehub\\datasets\\andrewmvd\\face-mask-detection\\versions\\1\n",
      "Copied to: D:\\AI\\NTI AI\\Face Mask Detection\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/face-mask-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "# Step 2: Copy data to working directory and extract\n",
    "dst_path = r\"D:\\AI\\NTI AI\\Face Mask Detection\"\n",
    "shutil.copytree(path, dst_path, dirs_exist_ok=True)\n",
    "print(\"Copied to:\", dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9b4e6",
   "metadata": {},
   "source": [
    "Dealing With GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b1ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#clear cache\n",
    "x=torch.cuda.empty_cache()\n",
    "print(x)\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a850e4",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adf1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import yaml\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageEnhance\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c3ec3",
   "metadata": {},
   "source": [
    "Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bfb8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r\"D:\\AI\\NTI AI\\Face Mask Detection\"\n",
    "img_dir = os.path.join(base_dir, \"images\")\n",
    "xml_dir = os.path.join(base_dir, \"annotations\")\n",
    "aug_dir = os.path.join(base_dir, \"augmented\")\n",
    "all_img_dir = os.path.join(base_dir, \"images_all\")\n",
    "all_xml_dir = os.path.join(base_dir, \"annotations_all\")\n",
    "preprocessed_dir = os.path.join(base_dir, \"images_preprocessed\")\n",
    "yolo_dir = os.path.join(base_dir, \"yolo_dataset_fixed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcecf0",
   "metadata": {},
   "source": [
    "Create Yolo Strcucture and Class Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "620f3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DIRECTORIES\n",
    "for folder in [aug_dir, all_img_dir, all_xml_dir, preprocessed_dir]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"annotations\"), exist_ok=True)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(yolo_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(yolo_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# CLASS MAP\n",
    "class_map = {\"with_mask\": 0, \"without_mask\": 1, \"mask_weared_incorrect\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f19eb0",
   "metadata": {},
   "source": [
    "Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d19e9",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26af636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  AUGMENT IMAGE\n",
    "def augment_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    if random.random() > 0.5:\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(random.uniform(0.7, 1.3))\n",
    "    angle = random.randint(-10, 10)\n",
    "    return img.rotate(angle)\n",
    "\n",
    "# AUGMENT RARE CLASS\n",
    "rare_class = \"mask_weared_incorrect\"\n",
    "aug_factor = 3\n",
    "image_files = [f for f in os.listdir(img_dir) if f.endswith(\".png\")]\n",
    "for img_file in image_files:\n",
    "    xml_file = img_file.replace(\".png\", \".xml\")\n",
    "    xml_path = os.path.join(xml_dir, xml_file)\n",
    "    if not os.path.exists(xml_path):\n",
    "        continue\n",
    "    with open(xml_path) as f:\n",
    "        if rare_class not in f.read():\n",
    "            continue\n",
    "    for i in range(aug_factor):\n",
    "        new_img = augment_image(os.path.join(img_dir, img_file))\n",
    "        aug_name = img_file.replace(\".png\", f\"_aug{i}.png\")\n",
    "        new_img.save(os.path.join(aug_dir, \"images\", aug_name))\n",
    "        shutil.copy(xml_path, os.path.join(aug_dir, \"annotations\", xml_file.replace(\".xml\", f\"_aug{i}.xml\")))\n",
    "\n",
    "#  MERGE ORIGINAL + AUGMENTED\n",
    "for src in [img_dir, os.path.join(aug_dir, \"images\")]:\n",
    "    for f in os.listdir(src):\n",
    "        shutil.copy(os.path.join(src, f), os.path.join(all_img_dir, f))\n",
    "\n",
    "for src in [xml_dir, os.path.join(aug_dir, \"annotations\")]:\n",
    "    for f in os.listdir(src):\n",
    "        shutil.copy(os.path.join(src, f), os.path.join(all_xml_dir, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99bbf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(img_path, out_path, size=(640, 640)):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\" Cannot read: {img_path}\")\n",
    "        return\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(out_path, img)\n",
    "\n",
    "for img_file in os.listdir(all_img_dir):\n",
    "    if not img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue  # skip non-image files/folders\n",
    "    src_path = os.path.join(all_img_dir, img_file)\n",
    "    dst_path = os.path.join(preprocessed_dir, img_file)\n",
    "    preprocess_image(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e85ebd5",
   "metadata": {},
   "source": [
    "Convert XML to Yolo Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26714d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_yolo(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "    lines, classes = [], []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        cls = obj.find(\"name\").text\n",
    "        if cls not in class_map:\n",
    "            continue\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(float(bbox.find(\"xmin\").text))\n",
    "        ymin = int(float(bbox.find(\"ymin\").text))\n",
    "        xmax = int(float(bbox.find(\"xmax\").text))\n",
    "        ymax = int(float(bbox.find(\"ymax\").text))\n",
    "        x_center = ((xmin + xmax) / 2) / width\n",
    "        y_center = ((ymin + ymax) / 2) / height\n",
    "        w = (xmax - xmin) / width\n",
    "        h = (ymax - ymin) / height\n",
    "        lines.append(f\"{class_map[cls]} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "        classes.append(cls)\n",
    "    return '\\n'.join(lines), classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e9a3b",
   "metadata": {},
   "source": [
    "Split Data and Save Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78576e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split and saved to YOLO format.\n",
      "Total images in Train: 1041\n",
      "Total labels: 1041\n",
      "Total images in Validation: 528\n",
      "Total labels: 528\n",
      "Total images in Test: 293\n",
      "Total labels: 293\n"
     ]
    }
   ],
   "source": [
    "#  SPLIT DATA\n",
    "all_data = []\n",
    "image_files = [f for f in os.listdir(preprocessed_dir) if f.endswith(\".png\")]\n",
    "for img_file in image_files:\n",
    "    xml_path = os.path.join(all_xml_dir, img_file.replace(\".png\", \".xml\"))\n",
    "    if not os.path.exists(xml_path):\n",
    "        continue\n",
    "    yolo_txt, _ = xml_to_yolo(xml_path)\n",
    "    if yolo_txt.strip():\n",
    "        all_data.append((img_file, yolo_txt))\n",
    "\n",
    "train_val, test = train_test_split(all_data, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=2/9, random_state=42)\n",
    "\n",
    "#  SAVE SPLITS\n",
    "\n",
    "def save_split(data, split):\n",
    "    for img_file, yolo_annots in data:\n",
    "        shutil.copy(os.path.join(preprocessed_dir, img_file), os.path.join(yolo_dir, \"images\", split, img_file))\n",
    "        label_file = img_file.replace(\".png\", \".txt\")\n",
    "        with open(os.path.join(yolo_dir, \"labels\", split, label_file), \"w\") as f:\n",
    "            f.write(yolo_annots)\n",
    "\n",
    "save_split(train, \"train\")\n",
    "save_split(val, \"val\")\n",
    "save_split(test, \"test\")\n",
    "#Show Number of images and labels in each split\n",
    "print(\"Data split and saved to YOLO format.\")\n",
    "print(\"Total images in Train:\", len(os.listdir(os.path.join(yolo_dir, \"images\", \"train\"))))\n",
    "print(\"Total labels:\", len(os.listdir(os.path.join(yolo_dir, \"labels\", \"train\"))))     \n",
    "print(\"Total images in Validation:\", len(os.listdir(os.path.join(yolo_dir, \"images\", \"val\"))))\n",
    "print(\"Total labels:\", len(os.listdir(os.path.join(yolo_dir, \"labels\", \"val\"))))\n",
    "print(\"Total images in Test:\", len(os.listdir(os.path.join(yolo_dir, \"images\", \"test\"))))\n",
    "print(\"Total labels:\", len(os.listdir(os.path.join(yolo_dir, \"labels\", \"test\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f690c01c",
   "metadata": {},
   "source": [
    "Yolo works with Yaml-->so make Yaml Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6998f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = os.path.join(yolo_dir, \"dataset.yaml\")\n",
    "yaml_content = {\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"test\": \"images/test\",\n",
    "    \"nc\": 3,\n",
    "    \"names\": [\"with_mask\", \"without_mask\", \"mask_weared_incorrect\"]\n",
    "}\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(yaml_content, f, sort_keys=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee011a",
   "metadata": {},
   "source": [
    "Train Yolo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc71e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.160 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.70  Python-3.9.0 torch-2.6.0+cu118 CPU (12th Gen Intel Core(TM) i5-12450HX)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:\\AI\\NTI AI\\Face Mask Detection\\yolo_dataset_fixed\\dataset.yaml, epochs=50, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=1, cache=False, device=cpu, workers=8, project=None, name=face_mask_augmented_preprocessed8, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\AI\\NTI AI\\Face Mask Detection\\yolo_dataset_fixed\\labels\\train.cache... 1041 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1041/1041 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\AI\\NTI AI\\Face Mask Detection\\yolo_dataset_fixed\\labels\\val.cache... 528 images, 0 backgrounds, 0 corrupt: 100%|██████████| 528/528 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.861      2.322      1.416          5        640: 100%|██████████| 131/131 [04:05<00:00,  1.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:49<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842     0.0781       0.17     0.0641     0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.655      1.678      1.318          4        640: 100%|██████████| 131/131 [04:47<00:00,  2.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:33<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.463      0.388      0.387      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G       1.59      1.588      1.303         10        640: 100%|██████████| 131/131 [03:32<00:00,  1.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:33<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.454      0.394      0.386      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.588      1.541      1.287         11        640: 100%|██████████| 131/131 [03:30<00:00,  1.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:32<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.536      0.447      0.448      0.274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G       1.59      1.481      1.298          9        640: 100%|██████████| 131/131 [03:39<00:00,  1.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:33<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.653      0.495      0.521      0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.527      1.369      1.269          3        640: 100%|██████████| 131/131 [05:53<00:00,  2.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:33<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.726      0.474       0.51      0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.517      1.339      1.245          7        640: 100%|██████████| 131/131 [09:00<00:00,  4.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [01:25<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.728      0.498      0.541      0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.516      1.349      1.252          2        640: 100%|██████████| 131/131 [06:32<00:00,  2.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [01:57<00:00,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.655      0.565      0.585      0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.491      1.283      1.226         17        640: 100%|██████████| 131/131 [12:48<00:00,  5.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [01:02<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.688      0.521       0.57      0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      1.489      1.289       1.22          7        640: 100%|██████████| 131/131 [04:21<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:39<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.728      0.586      0.626      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.454      1.248      1.229         17        640: 100%|██████████| 131/131 [04:09<00:00,  1.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.761      0.567      0.629      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      1.476      1.292      1.247          3        640: 100%|██████████| 131/131 [04:26<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:43<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842       0.61      0.514       0.53      0.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G      1.447      1.219      1.224         13        640: 100%|██████████| 131/131 [04:29<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.781      0.583       0.64      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      1.451      1.196      1.214         23        640: 100%|██████████| 131/131 [04:28<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.738       0.59      0.638      0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G      1.442      1.213      1.213         21        640: 100%|██████████| 131/131 [04:25<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842       0.76      0.562      0.622      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G      1.421      1.141      1.203          9        640: 100%|██████████| 131/131 [14:25<00:00,  6.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [02:24<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.819      0.615      0.675      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.417       1.16      1.211          4        640: 100%|██████████| 131/131 [13:04<00:00,  5.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.786      0.621      0.675      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G      1.398        1.1      1.188          5        640: 100%|██████████| 131/131 [04:29<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.768      0.562      0.633      0.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G      1.399      1.127      1.186          1        640: 100%|██████████| 131/131 [04:26<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.786       0.62      0.669      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G       1.36      1.091       1.17         29        640: 100%|██████████| 131/131 [04:27<00:00,  2.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.814       0.64      0.699      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G      1.363      1.113      1.177          1        640: 100%|██████████| 131/131 [04:30<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.798      0.617      0.691       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G      1.354      1.045      1.164          5        640: 100%|██████████| 131/131 [04:31<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.806      0.651      0.711      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G      1.363      1.058      1.162          9        640: 100%|██████████| 131/131 [04:29<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842       0.76      0.629      0.679      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G      1.316      1.037      1.151         17        640: 100%|██████████| 131/131 [04:22<00:00,  2.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:40<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.779      0.621      0.674      0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G      1.341     0.9991      1.167          8        640: 100%|██████████| 131/131 [04:28<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.806      0.649      0.704      0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G      1.341      1.034      1.159          3        640: 100%|██████████| 131/131 [04:29<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.817      0.653      0.714      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G      1.326      1.015      1.134         12        640: 100%|██████████| 131/131 [04:29<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.821       0.65      0.713      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G      1.328      1.025       1.15          4        640: 100%|██████████| 131/131 [04:32<00:00,  2.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.843      0.643      0.721      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G      1.283     0.9874      1.137          5        640: 100%|██████████| 131/131 [04:30<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.821      0.658      0.736       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G      1.293     0.9757      1.136         22        640: 100%|██████████| 131/131 [04:21<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.883      0.632      0.732      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G      1.313       1.01      1.146          1        640: 100%|██████████| 131/131 [04:31<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.835      0.685      0.745      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G      1.268     0.9275      1.126         14        640: 100%|██████████| 131/131 [04:23<00:00,  2.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.808      0.676      0.735      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G      1.267      0.936      1.122          2        640: 100%|██████████| 131/131 [04:25<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.839       0.68      0.733      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G      1.269     0.9597      1.124          2        640: 100%|██████████| 131/131 [04:30<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.804      0.705      0.747      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G      1.248     0.9118      1.124          4        640: 100%|██████████| 131/131 [04:25<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.825      0.692      0.755      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G      1.272      0.943      1.127          8        640: 100%|██████████| 131/131 [04:30<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.872      0.676       0.75      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G      1.241     0.9209      1.113          5        640: 100%|██████████| 131/131 [04:26<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:40<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.854      0.681      0.745      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G      1.244     0.9055      1.105          3        640: 100%|██████████| 131/131 [04:31<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.824      0.678      0.743      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G      1.253     0.9127      1.113         15        640: 100%|██████████| 131/131 [04:29<00:00,  2.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.856       0.69      0.758      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G      1.254     0.8995      1.114         20        640: 100%|██████████| 131/131 [04:31<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.852      0.693      0.761      0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G      1.218     0.8859      1.114          3        640: 100%|██████████| 131/131 [04:24<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.828      0.702      0.754       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G      1.226      0.888      1.114         18        640: 100%|██████████| 131/131 [04:26<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.831      0.695      0.756      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G      1.206     0.8771      1.116          2        640: 100%|██████████| 131/131 [04:26<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.843       0.71      0.764      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G      1.215     0.8602      1.117          1        640: 100%|██████████| 131/131 [04:24<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.868      0.679      0.761      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G      1.183     0.8468      1.101         14        640: 100%|██████████| 131/131 [04:25<00:00,  2.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.832      0.709      0.762      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G      1.216     0.8916      1.113         13        640: 100%|██████████| 131/131 [04:23<00:00,  2.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842       0.84      0.704      0.765      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G       1.19     0.8504      1.099          1        640: 100%|██████████| 131/131 [04:17<00:00,  1.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.827      0.715      0.764      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G      1.179     0.8481      1.099          1        640: 100%|██████████| 131/131 [04:21<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:42<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.817      0.714      0.764      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G      1.179     0.8443      1.095          3        640: 100%|██████████| 131/131 [04:22<00:00,  2.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.855      0.696      0.767      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G       1.18      0.856      1.101          2        640: 100%|██████████| 131/131 [04:25<00:00,  2.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [00:41<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.857      0.696      0.766      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 4.891 hours.\n",
      "Optimizer stripped from C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\\weights\\best.pt...\n",
      "Ultralytics 8.3.70  Python-3.9.0 torch-2.6.0+cu118 CPU (12th Gen Intel Core(TM) i5-12450HX)\n",
      "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 33/33 [01:13<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        528       2842      0.829      0.694      0.758      0.524\n",
      "             with_mask        450       2159      0.886      0.816      0.863      0.608\n",
      "          without_mask        195        499        0.8      0.721      0.764      0.514\n",
      " mask_weared_incorrect        147        184      0.801      0.543      0.649       0.45\n",
      "Speed: 1.0ms preprocess, 114.0ms inference, 0.0ms loss, 8.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Try to load model safely, will auto-download if missing or corrupted\n",
    "try:\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ YOLOv8n model file corrupted or missing. Downloading fresh copy...\")\n",
    "    model = YOLO(\"yolov8n\")  # 'yolov8n' will trigger auto-download\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=50,\n",
    "    batch=8,\n",
    "    imgsz=640,\n",
    "    device='cpu',  # better with GPU, but using CPU for problems in my device\n",
    "    name=\"face_mask_augmented_preprocessed\",\n",
    "    optimizer=\"Adam\",\n",
    "    lr0=0.001,\n",
    "    weight_decay=0.0005,\n",
    "    cos_lr=True,\n",
    "    lrf=0.01,\n",
    "    augment=True,\n",
    "    patience=10,\n",
    "    save=True,\n",
    "    save_period=1,\n",
    "    val=True,\n",
    "    plots=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e32461",
   "metadata": {},
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8e04c5",
   "metadata": {},
   "source": [
    "IoU-->Intersection over Union=Area of Overlap/Area of Union\n",
    "Overlap-->How much predicted box covers real object\n",
    "Union=Area of predicted box+Area of Real Box-Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4172f49",
   "metadata": {},
   "source": [
    "Box Loss-->How tight Box is\n",
    "CLS Loss-->How correct predicted class label is\n",
    "DFL Loss-->How Confident the model is about the exact location of box edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48d5232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.70  Python-3.9.0 torch-2.6.0+cu118 CPU (12th Gen Intel Core(TM) i5-12450HX)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\AI\\NTI AI\\Face Mask Detection\\yolo_dataset_fixed\\labels\\test.cache... 293 images, 0 backgrounds, 0 corrupt: 100%|██████████| 293/293 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 37/37 [01:03<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        293       1949      0.817       0.66      0.709      0.489\n",
      "             with_mask        262       1437      0.882      0.772      0.819      0.576\n",
      "          without_mask        108        383      0.789      0.665      0.711      0.467\n",
      " mask_weared_incorrect         96        129      0.779      0.543      0.597      0.422\n",
      "Speed: 1.3ms preprocess, 159.1ms inference, 0.0ms loss, 14.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_augmented_preprocessed82\u001b[0m\n",
      "✅ Test Evaluation Complete.\n",
      "mAP@50: 0.709\n",
      "mAP@50-95: 0.489\n",
      "Mean Precision: 0.817\n",
      "Mean Recall: 0.660\n",
      "\n",
      "📊 Class-wise Precision, Recall, F1 Score:\n",
      "with_mask                 P=0.882  R=0.772  F1=0.823\n",
      "without_mask              P=0.789  R=0.665  F1=0.722\n",
      "mask_weared_incorrect     P=0.779  R=0.543  F1=0.640\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=yaml_path, split=\"test\")\n",
    "\n",
    "print(\"✅ Test Evaluation Complete.\")\n",
    "print(f\"mAP@50: {metrics.box.map50:.3f}\")       # Good if > 0.7\n",
    "print(f\"mAP@50-95: {metrics.box.map:.3f}\")      # Good if > 0.4\n",
    "print(f\"Mean Precision: {metrics.box.mp:.3f}\") #Of models detection,How many are correct\n",
    "print(f\"Mean Recall: {metrics.box.mr:.3f}\")     #of all real objects,how many did the model find\n",
    "\n",
    "# Optional: Class-wise metrics\n",
    "print(\"\\n📊 Class-wise Precision, Recall, F1 Score:\")\n",
    "for i, name in metrics.names.items():\n",
    "    p = metrics.box.p[i]\n",
    "    r = metrics.box.r[i]\n",
    "    f1 = metrics.box.f1[i]\n",
    "    print(f\"{name:<25} P={p:.3f}  R={r:.3f}  F1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f340a",
   "metadata": {},
   "source": [
    "Prediction Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd414f",
   "metadata": {},
   "source": [
    "With Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc3105",
   "metadata": {},
   "source": [
    "The **confidence score** is a metric that represents how sure the model is that the detected object belongs to a specific class, ranging from 0 (not confident) to 1 (very confident).,It appears after Picture \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a8fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\AI\\NTI AI\\images.jpg: 640x448 1 with_mask, 98.2ms\n",
      "Speed: 6.3ms preprocess, 98.2ms inference, 408.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Results saved to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\predict18\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(r\"C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_detection5\\weights\\best.pt\")\n",
    "\n",
    "# Image path\n",
    "image_path = r\"D:\\AI\\NTI AI\\images.jpg\"\n",
    "\n",
    "# Run prediction with confidence threshold\n",
    "results = model.predict(source=image_path, save=True, conf=0.5)\n",
    "\n",
    "# Plot using OpenCV\n",
    "for result in results:\n",
    "    image_with_boxes = result.plot()\n",
    "    cv2.imshow(\"YOLOv8 Detection\", image_with_boxes)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Plot using Matplotlib (optional)\n",
    "plt.imshow(cv2.cvtColor(results[0].plot(), cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Detection Results\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086fcfea",
   "metadata": {},
   "source": [
    "Predict without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "439651d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\AI\\NTI AI\\images (1).jpg: 384x640 1 without_mask, 33.9ms\n",
      "Speed: 3.0ms preprocess, 33.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\predict15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(r\"C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_detection5\\weights\\best.pt\")\n",
    "\n",
    "# Predict on single image\n",
    "image_path = r\"D:\\AI\\NTI AI\\images (1).jpg\"\n",
    "results = model.predict(source=image_path, save=True, conf=0.5)\n",
    "\n",
    "# Show results (optional)\n",
    "for result in results:\n",
    "    cv2.imshow(\"Detection\", result.plot())\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b986136",
   "metadata": {},
   "source": [
    "Predict multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5348696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\AI\\NTI AI\\360_F_359987183_Hgu1X29BvLQ1t46CVXUVYDY4PPPHpvrw.jpg: 448x640 1 with_mask, 76.5ms\n",
      "Speed: 7.4ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\predict19\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(r\"C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_detection5\\weights\\best.pt\")\n",
    "\n",
    "# Predict on single image\n",
    "image_path = r\"D:\\AI\\NTI AI\\360_F_359987183_Hgu1X29BvLQ1t46CVXUVYDY4PPPHpvrw.jpg\"\n",
    "results = model.predict(source=image_path, save=True, conf=0.5)\n",
    "\n",
    "# Show results (optional)\n",
    "for result in results:\n",
    "    cv2.imshow(\"Detection\", result.plot())\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6f35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\AI\\NTI AI\\images (2).jpg: 256x640 2 with_masks, 2 without_masks, 85.5ms\n",
      "Speed: 6.3ms preprocess, 85.5ms inference, 6.4ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\lenovo\\ultralytics\\runs\\detect\\predict20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(r\"C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_detection5\\weights\\best.pt\")\n",
    "\n",
    "# Predict on single image\n",
    "image_path = r\"D:\\AI\\NTI AI\\images (2).jpg\"\n",
    "results = model.predict(source=image_path, save=True, conf=0.5)\n",
    "\n",
    "# Show results (optional)\n",
    "for result in results:\n",
    "    cv2.imshow(\"Detection\", result.plot())\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e35691",
   "metadata": {},
   "source": [
    "Using WebCam (Real Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "389a68a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟡 Loading model...\n",
      "✅ Model loaded successfully.\n",
      "🎥 Initializing webcam...\n",
      "🚀 Detection started. Press 'Q' to quit.\n",
      "🔍 Detected: without_mask (0.80)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.82)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.81)\n",
      "🔍 Detected: without_mask (0.78)\n",
      "🔍 Detected: without_mask (0.80)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.77)\n",
      "🔍 Detected: without_mask (0.78)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: without_mask (0.57)\n",
      "🔍 Detected: without_mask (0.57)\n",
      "🔍 Detected: without_mask (0.64)\n",
      "🔍 Detected: without_mask (0.56)\n",
      "🔍 Detected: without_mask (0.77)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: without_mask (0.74)\n",
      "🔍 Detected: without_mask (0.78)\n",
      "🔍 Detected: without_mask (0.61)\n",
      "🔍 Detected: without_mask (0.77)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.96)\n",
      "🔍 Detected: without_mask (0.94)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.94)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.82)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.81)\n",
      "🔍 Detected: without_mask (0.82)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.80)\n",
      "🔍 Detected: without_mask (0.80)\n",
      "🔍 Detected: without_mask (0.63)\n",
      "🔍 Detected: mask_weared_incorrect (0.62)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.77)\n",
      "🔍 Detected: mask_weared_incorrect (0.65)\n",
      "🔍 Detected: with_mask (0.60)\n",
      "🔍 Detected: with_mask (0.58)\n",
      "🔍 Detected: with_mask (0.64)\n",
      "🔍 Detected: with_mask (0.59)\n",
      "🔍 Detected: with_mask (0.51)\n",
      "🔍 Detected: with_mask (0.69)\n",
      "🔍 Detected: with_mask (0.78)\n",
      "🔍 Detected: with_mask (0.80)\n",
      "🔍 Detected: with_mask (0.81)\n",
      "🔍 Detected: with_mask (0.80)\n",
      "🔍 Detected: with_mask (0.88)\n",
      "🔍 Detected: with_mask (0.89)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.89)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.88)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.89)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.95)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.71)\n",
      "🔍 Detected: with_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: without_mask (0.56)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: without_mask (0.67)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.68)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.77)\n",
      "🔍 Detected: without_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.66)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: without_mask (0.69)\n",
      "🔍 Detected: mask_weared_incorrect (0.61)\n",
      "🔍 Detected: without_mask (0.72)\n",
      "🔍 Detected: mask_weared_incorrect (0.63)\n",
      "🔍 Detected: without_mask (0.77)\n",
      "🔍 Detected: mask_weared_incorrect (0.61)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: without_mask (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.67)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.58)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.73)\n",
      "🔍 Detected: without_mask (0.72)\n",
      "🔍 Detected: without_mask (0.74)\n",
      "🔍 Detected: without_mask (0.82)\n",
      "🔍 Detected: without_mask (0.81)\n",
      "🔍 Detected: without_mask (0.80)\n",
      "🔍 Detected: without_mask (0.78)\n",
      "🔍 Detected: without_mask (0.76)\n",
      "🔍 Detected: without_mask (0.74)\n",
      "🔍 Detected: without_mask (0.65)\n",
      "🔍 Detected: without_mask (0.63)\n",
      "🔍 Detected: mask_weared_incorrect (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.66)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.73)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.72)\n",
      "🔍 Detected: without_mask (0.65)\n",
      "🔍 Detected: mask_weared_incorrect (0.73)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: mask_weared_incorrect (0.76)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.76)\n",
      "🔍 Detected: without_mask (0.55)\n",
      "🔍 Detected: mask_weared_incorrect (0.72)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.55)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.56)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.63)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: without_mask (0.51)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: without_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.67)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.97)\n",
      "🔍 Detected: mask_weared_incorrect (0.97)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: without_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: without_mask (0.56)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.51)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.65)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.51)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.56)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.56)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: without_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.96)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.64)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.68)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: without_mask (0.63)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: without_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: without_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.78)\n",
      "🔍 Detected: mask_weared_incorrect (0.77)\n",
      "🔍 Detected: mask_weared_incorrect (0.78)\n",
      "🔍 Detected: mask_weared_incorrect (0.51)\n",
      "🔍 Detected: with_mask (0.68)\n",
      "🔍 Detected: with_mask (0.81)\n",
      "🔍 Detected: with_mask (0.87)\n",
      "🔍 Detected: with_mask (0.86)\n",
      "🔍 Detected: with_mask (0.84)\n",
      "🔍 Detected: with_mask (0.86)\n",
      "🔍 Detected: with_mask (0.88)\n",
      "🔍 Detected: with_mask (0.88)\n",
      "🔍 Detected: with_mask (0.88)\n",
      "🔍 Detected: with_mask (0.87)\n",
      "🔍 Detected: with_mask (0.88)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.90)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.91)\n",
      "🔍 Detected: with_mask (0.92)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.94)\n",
      "🔍 Detected: with_mask (0.93)\n",
      "🔍 Detected: with_mask (0.89)\n",
      "🔍 Detected: with_mask (0.89)\n",
      "🔍 Detected: with_mask (0.89)\n",
      "🔍 Detected: with_mask (0.85)\n",
      "🔍 Detected: with_mask (0.84)\n",
      "🔍 Detected: with_mask (0.80)\n",
      "🔍 Detected: with_mask (0.78)\n",
      "🔍 Detected: with_mask (0.77)\n",
      "🔍 Detected: with_mask (0.73)\n",
      "🔍 Detected: with_mask (0.76)\n",
      "🔍 Detected: with_mask (0.79)\n",
      "🔍 Detected: with_mask (0.78)\n",
      "🔍 Detected: with_mask (0.79)\n",
      "🔍 Detected: with_mask (0.77)\n",
      "🔍 Detected: with_mask (0.77)\n",
      "🔍 Detected: with_mask (0.79)\n",
      "🔍 Detected: with_mask (0.77)\n",
      "🔍 Detected: with_mask (0.82)\n",
      "🔍 Detected: with_mask (0.81)\n",
      "🔍 Detected: with_mask (0.83)\n",
      "🔍 Detected: with_mask (0.84)\n",
      "🔍 Detected: with_mask (0.79)\n",
      "🔍 Detected: with_mask (0.77)\n",
      "🔍 Detected: mask_weared_incorrect (0.57)\n",
      "🔍 Detected: with_mask (0.74)\n",
      "🔍 Detected: mask_weared_incorrect (0.71)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: without_mask (0.73)\n",
      "🔍 Detected: mask_weared_incorrect (0.70)\n",
      "🔍 Detected: without_mask (0.81)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.94)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.94)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.94)\n",
      "🔍 Detected: without_mask (0.94)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.93)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.81)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.87)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.92)\n",
      "🔍 Detected: without_mask (0.91)\n",
      "🔍 Detected: without_mask (0.90)\n",
      "🔍 Detected: without_mask (0.88)\n",
      "🔍 Detected: without_mask (0.89)\n",
      "🔍 Detected: without_mask (0.86)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.85)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.84)\n",
      "🔍 Detected: without_mask (0.78)\n",
      "🔍 Detected: without_mask (0.72)\n",
      "🔍 Detected: without_mask (0.72)\n",
      "🔍 Detected: without_mask (0.69)\n",
      "🔍 Detected: without_mask (0.65)\n",
      "🔍 Detected: without_mask (0.68)\n",
      "🔍 Detected: without_mask (0.68)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: without_mask (0.67)\n",
      "🔍 Detected: without_mask (0.53)\n",
      "🔍 Detected: without_mask (0.66)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: without_mask (0.68)\n",
      "🔍 Detected: without_mask (0.51)\n",
      "🔍 Detected: without_mask (0.68)\n",
      "🔍 Detected: without_mask (0.51)\n",
      "🔍 Detected: without_mask (0.68)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: without_mask (0.69)\n",
      "🔍 Detected: without_mask (0.70)\n",
      "🔍 Detected: without_mask (0.76)\n",
      "🔍 Detected: without_mask (0.73)\n",
      "🔍 Detected: without_mask (0.74)\n",
      "🔍 Detected: without_mask (0.75)\n",
      "🔍 Detected: without_mask (0.81)\n",
      "🔍 Detected: without_mask (0.83)\n",
      "🔍 Detected: without_mask (0.82)\n",
      "🔍 Detected: without_mask (0.79)\n",
      "🔍 Detected: without_mask (0.79)\n",
      "🔍 Detected: without_mask (0.76)\n",
      "🔍 Detected: without_mask (0.73)\n",
      "🔍 Detected: without_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: without_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: without_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: with_mask (0.50)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: with_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: with_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: with_mask (0.51)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: with_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: with_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: with_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: with_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: with_mask (0.60)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: with_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: with_mask (0.58)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: with_mask (0.55)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: with_mask (0.55)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: with_mask (0.52)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: with_mask (0.54)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: with_mask (0.56)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: with_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.79)\n",
      "🔍 Detected: with_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.76)\n",
      "🔍 Detected: with_mask (0.62)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: with_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: with_mask (0.53)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: with_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.94)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.80)\n",
      "🔍 Detected: mask_weared_incorrect (0.80)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.84)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.86)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.92)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.85)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: with_mask (0.55)\n",
      "🔍 Detected: mask_weared_incorrect (0.78)\n",
      "🔍 Detected: with_mask (0.61)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: with_mask (0.57)\n",
      "🔍 Detected: mask_weared_incorrect (0.79)\n",
      "🔍 Detected: with_mask (0.59)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.95)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.93)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🔍 Detected: mask_weared_incorrect (0.88)\n",
      "🔍 Detected: mask_weared_incorrect (0.89)\n",
      "🔍 Detected: mask_weared_incorrect (0.90)\n",
      "🔍 Detected: mask_weared_incorrect (0.81)\n",
      "🔍 Detected: mask_weared_incorrect (0.82)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.83)\n",
      "🔍 Detected: mask_weared_incorrect (0.87)\n",
      "🔍 Detected: mask_weared_incorrect (0.91)\n",
      "🛑 Program ended. Webcam released.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    print(\"🟡 Loading model...\")\n",
    "    model_path = r\"C:\\Users\\lenovo\\ultralytics\\runs\\detect\\face_mask_detection5\\weights\\best.pt\"\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(\"✅ Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"🎥 Initializing webcam...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Error: Webcam not accessible.\")\n",
    "        return\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    time.sleep(1)  # Give camera some time to warm up\n",
    "\n",
    "    print(\"🚀 Detection started. Press 'Q' to quit.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"⚠️ Failed to read frame. Retrying...\")\n",
    "                continue\n",
    "\n",
    "            # Run detection\n",
    "            results = model.predict(frame, conf=0.5, verbose=False)\n",
    "            annotated_frame = frame  # fallback\n",
    "\n",
    "            # Plot only if results exist\n",
    "            if results and len(results[0].boxes) > 0:\n",
    "                annotated_frame = results[0].plot()\n",
    "\n",
    "                # Optional: print all detections\n",
    "                for box in results[0].boxes:\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    label = model.names[cls_id]\n",
    "                    print(f\"🔍 Detected: {label} ({conf:.2f})\")\n",
    "\n",
    "            # Display\n",
    "            cv2.imshow(\"Face Mask Detection (Press Q)\", annotated_frame)\n",
    "\n",
    "            # Exit on 'Q'\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❗ Runtime error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"🛑 Program ended. Webcam released.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
